{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3750beb3",
   "metadata": {},
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6a9782f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d0e2c838f27a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertForQuestionAnswering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForQuestionAnswering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import nltk\n",
    "from transformers import BertForQuestionAnswering, AutoModelForQuestionAnswering, BertTokenizer, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987d2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "# model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "# Tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "# tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a7dfe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query and Context\n",
    "from queries import get_text_cli\n",
    "from get_documents import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3b3ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def query_and_context():\n",
    "    term = get_text_cli('Enter a search term')\n",
    "    context = search(term)\n",
    "    query = get_text_cli(\"Enter your question\")\n",
    "    return {\n",
    "        'query': query, \n",
    "        'context_id': context[0], \n",
    "        'context_title': context[1], \n",
    "        'context': context[2]\n",
    "    }\n",
    "\n",
    "def segment_text(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    segments = []\n",
    "    while tokens:\n",
    "        segments.append(' '.join(tokens[:512]))\n",
    "        del tokens[:512]\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8841e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Inference\n",
    "def run_model(query, text):\n",
    "    # Initialising model\n",
    "    model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "    \n",
    "    # Initialising tokeniser\n",
    "    tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        query,\n",
    "        text,\n",
    "        max_length=100,\n",
    "        truncation=\"only_second\",\n",
    "        stride=50,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    # Running model\n",
    "    output = model(\n",
    "        input_ids=torch.tensor([inputs['input_ids'][0]]), \n",
    "        token_type_ids=torch.tensor(inputs['token_type_ids'][0])\n",
    "    )\n",
    "    \n",
    "    # Putting answer together\n",
    "    start_i = torch.argmax(output['start_logits'])\n",
    "    end_i = torch.argmax(output['end_logits'])\n",
    "    (start_i, end_i)\n",
    "    \n",
    "    answer = ' '.join(tokens[start_i:end_i+1])\n",
    "    corrected_answer = ''\n",
    "    for word in answer.split():\n",
    "        #If it's a subword token\n",
    "        if word[0:2] == '##':\n",
    "            corrected_answer += word[2:]\n",
    "        else:\n",
    "            corrected_answer += ' ' + word\n",
    "    \n",
    "    return corrected_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c8cc7",
   "metadata": {},
   "source": [
    "## Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11e8ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_idf import tokenize\n",
    "# word_dict = query_and_context()\n",
    "# word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57e9662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_rank(query, context, n=0):\n",
    "#     query_set = set(tokenize(query))\n",
    "#     sentences = {sent: tokenize(sent) for sent in nltk.sent_tokenize(context)}\n",
    "#     sent_scores = { sent: 0 for sent in sentences}\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    sent_scores = {\n",
    "        sent: text_similarity(query, sent, model)\n",
    "        for sent in nltk.sent_tokenize(context)\n",
    "    }\n",
    "#     for sent in sentences:\n",
    "#         common_words = query_set.intersection(set(sentences[sent]))\n",
    "#         sent_scores[sent] += len(common_words)\n",
    "    \n",
    "    ranked_scores = sorted(\n",
    "        sent_scores.items(),\n",
    "        key = lambda x: x[1],\n",
    "    )\n",
    "    \n",
    "    return ranked_scores\n",
    "\n",
    "def build_input_text(ranked_sents, max_length=512):\n",
    "    input_text = ''\n",
    "    \n",
    "    while True:\n",
    "        new_sent = ranked_sents.pop()[0]\n",
    "        if len(nltk.word_tokenize(f'{input_text} {new_sent}')) <= max_length:\n",
    "            input_text += f' {new_sent}'\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return input_text\n",
    "\n",
    "def text_similarity(text_1, text_2, model):\n",
    "    embedding_1= model.encode(text_1, convert_to_tensor=True)\n",
    "    embedding_2 = model.encode(text_2, convert_to_tensor=True)\n",
    "    \n",
    "    return float(util.pytorch_cos_sim(embedding_1, embedding_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8db0180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_extraction_procedure():\n",
    "    word_dict = query_and_context()\n",
    "    ranked_sents = sent_rank(word_dict['query'], word_dict['context'], 0)\n",
    "    print(ranked_sents)\n",
    "    input_text = build_input_text(ranked_sents)\n",
    "    print(input_text)\n",
    "    model_output = run_model(word_dict['query'], input_text)\n",
    "    return word_dict['query'], model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc84136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question, answer = info_extraction_procedure()\n",
    "# print(f'Question: \"{question}\"', f'Answer: \"{answer}\"', sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f899b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question, answer = info_extraction_procedure()\n",
    "# print(f'Question: \"{question}\"', f'Answer: \"{answer}\"', sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a95ed9",
   "metadata": {},
   "source": [
    "# OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a232f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "393dd700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_info = query_and_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a8d8df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ranked_sents = sent_rank(text_info['query'], text_info['context'])\n",
    "# input_text = build_input_text(ranked_sents, 3500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b2e996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = \"https://api.openai.com/v1/completions\"\n",
    "# openai.api_key = \"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\"\n",
    "\n",
    "# res = openai.Completion.create(\n",
    "#     model=\"text-davinci-003\", \n",
    "#     prompt=f\"Context: {input_text} Query: {text_info['query']}\\n\\nUsing the context, answer the query.\", \n",
    "#     temperature=0,\n",
    "# )\n",
    "# res = req.get(\n",
    "#     base_url, \n",
    "#     headers={\n",
    "#         'Authorization': f'Bearer {api_key}',\n",
    "# #         'Content-Type': 'application/json'\n",
    "#     }, \n",
    "#     data={\n",
    "#         \"model\": \"text-davinci-003\", \n",
    "#         \"prompt\": \"Say this is a test\", \n",
    "#         \"temperature\": 0, \n",
    "#         \"max_tokens\": 7,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88a0e55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.choices[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5b72f0",
   "metadata": {},
   "source": [
    "# DocSearcher Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e047a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-Party Imports\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Standard Library Imports\n",
    "import os\n",
    "from string import punctuation\n",
    "from math import log1p, inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf61da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocSearcher():\n",
    "    def __init__(self):\n",
    "        self._corpus = dict()\n",
    "        self._file_matches = 2\n",
    "        self._sentence_matches = 1\n",
    "    \n",
    "    def view_corpus(self):\n",
    "        return self._corpus\n",
    "\n",
    "    def load_files(self, dirname):\n",
    "        main_path = os.path.join(os.path.dirname('__file__'), dirname)\n",
    "\n",
    "        for file in os.listdir(main_path):\n",
    "            with open(os.path.join(main_path, file), 'r') as f:\n",
    "                self._corpus[file] = f.read()\n",
    "    \n",
    "    def search(self, query, s_method='tf-idf', e_method='tf-idf', fnames=None):\n",
    "        if not fnames: fnames = self._corpus.keys()\n",
    "\n",
    "        if s_method == 'tf-idf':\n",
    "            joint_context, ranked_sents = self._context_and_sents_idf(query, fnames)\n",
    "        elif s_method == 'cosine_sim':\n",
    "            joint_context, ranked_sents = self._context_and_sents_cosine(query, fnames)\n",
    "        \n",
    "#         print(joint_context, ranked_sents, sep=\"\\n\\n\")\n",
    "        \n",
    "#         print(ranked_sents[:self._sentence_matches])\n",
    "        \n",
    "        if e_method == 'conjoin':\n",
    "            output_text = self._build_output_text(ranked_sents, inf)\n",
    "            answer = ' '.join(nltk.sent_tokenize(output_text)[:self._sentence_matches])\n",
    "        elif e_method == 'bert':\n",
    "            output_text = self._build_output_text(ranked_sents, 512)\n",
    "            answer = self._run_model_bert(query, output_text)\n",
    "        elif e_method == 'bert2':\n",
    "            output_text = self._build_output_text(ranked_sents, inf)\n",
    "            answer = self._run_model_bert2(query, output_text, 128)\n",
    "#             answer = self._run_model_bert2(query, joint_context, 128)\n",
    "        elif e_method == 'openai':\n",
    "            output_text = self._build_output_text(ranked_sents, 2500)\n",
    "            answer = self._run_model_openai(query, output_text)\n",
    "        \n",
    "        print('\\n\\nAnd the output is...\\n\\n', output_text)\n",
    "        return answer\n",
    "    \n",
    "    def _build_output_text(self, ranked_sents, max_length=512):\n",
    "        output_text = ''\n",
    "\n",
    "        for sent in ranked_sents:\n",
    "            new_sent = sent[0]\n",
    "            if len(nltk.word_tokenize(f'{output_text} {new_sent}')) <= max_length:\n",
    "                output_text += f' {new_sent}'\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return output_text\n",
    "    \n",
    "    def _run_model_bert(self, query, text):\n",
    "        # Initialising model\n",
    "        model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "        # Initialising tokeniser\n",
    "        tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            query,\n",
    "            text,\n",
    "            max_length=100,\n",
    "            truncation=\"only_second\",\n",
    "            stride=50,\n",
    "            return_overflowing_tokens=True,\n",
    "            return_offsets_mapping=True\n",
    "        )\n",
    "\n",
    "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "\n",
    "        # Running model\n",
    "        output = model(\n",
    "            input_ids=torch.tensor([inputs['input_ids'][0]]), \n",
    "            token_type_ids=torch.tensor(inputs['token_type_ids'][0])\n",
    "        )\n",
    "\n",
    "        # Putting answer together\n",
    "        start_i = torch.argmax(output['start_logits'])\n",
    "        end_i = torch.argmax(output['end_logits'])\n",
    "        (start_i, end_i)\n",
    "\n",
    "        answer = ' '.join(tokens[start_i:end_i+1])\n",
    "        corrected_answer = ''\n",
    "        for word in answer.split():\n",
    "            #If it's a subword token\n",
    "            if word[0:2] == '##':\n",
    "                corrected_answer += word[2:]\n",
    "            else:\n",
    "                corrected_answer += ' ' + word\n",
    "\n",
    "        return corrected_answer\n",
    "    \n",
    "    def _run_model_bert2(self, query, context, chunk_size=512):\n",
    "        # Initialise model and tokenizer\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "        model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "        \n",
    "        # Chunking\n",
    "        max_length = chunk_size\n",
    "        text_len = len(context)\n",
    "\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for i in range(0, text_len, max_length):\n",
    "            chunk = context[i:i+max_length]\n",
    "            encoded_dict = tokenizer.encode_plus(\n",
    "                question,\n",
    "                chunk,\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_length,\n",
    "                pad_to_max_length=True,\n",
    "                return_attention_mask=True,\n",
    "                return_tensors='pt',\n",
    "                truncation=True\n",
    "            )\n",
    "\n",
    "            input_ids.append(encoded_dict['input_ids'])\n",
    "            attention_masks.append(encoded_dict['attention_mask'])\n",
    "        \n",
    "        # Stack the chunks of input IDs and attention masks\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "        # Put the model in evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Predict the output\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask=attention_masks)\n",
    "            start_logits, end_logits = outputs[:2]\n",
    "        \n",
    "        for i in range(len(input_ids)):\n",
    "            # Get the start and end indices of the answer span\n",
    "            start_ind = torch.argmax(start_logits[i])\n",
    "            end_ind = torch.argmax(end_logits[i])\n",
    "\n",
    "            # Use the indices to get the answer span from the input text\n",
    "            answer_text = tokenizer.decode(input_ids[i, start_ind:end_ind + 1], skip_special_tokens=True)\n",
    "\n",
    "            # Print the answer span\n",
    "            print(\"Answer: \", answer_text)\n",
    "        \n",
    "        # Generate answer span\n",
    "        best_answer_ind = -1\n",
    "        max_start_logit = -1e10\n",
    "        max_end_logit = -1e10\n",
    "\n",
    "        for i in range(len(input_ids)):\n",
    "            # Get the start and end logits for this chunk\n",
    "            curr_start_logit = start_logits[i].max().item()\n",
    "            curr_end_logit = end_logits[i].max().item()\n",
    "\n",
    "            # Find the chunk with the highest start and end logits\n",
    "            if curr_start_logit + curr_end_logit > max_start_logit + max_end_logit:\n",
    "                max_start_logit = curr_start_logit\n",
    "                max_end_logit = curr_end_logit\n",
    "                best_answer_ind = i\n",
    "\n",
    "        # Use the best answer indices to get the answer span from the input text\n",
    "        start_ind = torch.argmax(start_logits[best_answer_ind])\n",
    "        end_ind = torch.argmax(end_logits[best_answer_ind])\n",
    "        answer_text = tokenizer.decode(\n",
    "            input_ids[best_answer_ind, start_ind:end_ind + 1], \n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        return answer_text\n",
    "        \n",
    "    def _run_model_openai(self, query, text):\n",
    "        openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "        res = openai.Completion.create(\n",
    "            model=\"text-davinci-003\", \n",
    "            prompt=f\"Context: {query} Query: {text}\\n\\nUsing only the context given, answer the query.\", \n",
    "            temperature=0,\n",
    "            max_tokens=500,\n",
    "        )\n",
    "        \n",
    "        return res.choices[0].text\n",
    "\n",
    "    def _context_and_sents_idf(self, query, fnames):\n",
    "        idfs = self._compute_idfs(fnames)\n",
    "        top_files = self._top_files_idf(query, idfs)\n",
    "\n",
    "        joint_context = \"\\n\".join(self._corpus[name] for name in top_files)\n",
    "\n",
    "        ranked_sents = self._sent_rank_idf(query, joint_context, idfs)\n",
    "\n",
    "        return joint_context, ranked_sents\n",
    "    \n",
    "    def _context_and_sents_cosine(self, query, fnames):\n",
    "        top_files = self._top_files_cosine(query, fnames)\n",
    "        joint_context = \"\\n\".join(self._corpus[name] for name in top_files)\n",
    "\n",
    "        ranked_sents = self._sent_rank_cosine(query, joint_context)\n",
    "\n",
    "        return joint_context, ranked_sents\n",
    "\n",
    "    def _cosine_similarity(self, text_1, text_2, model):\n",
    "        embedding_1= model.encode(text_1, convert_to_tensor=True)\n",
    "        embedding_2 = model.encode(text_2, convert_to_tensor=True)\n",
    "    \n",
    "        return float(util.pytorch_cos_sim(embedding_1, embedding_2))\n",
    "    \n",
    "    def _compute_idfs(self, fnames):\n",
    "        file_idfs = dict()\n",
    "        unique_words = set()\n",
    "        num_docs = len(fnames)\n",
    "\n",
    "        for name in fnames:\n",
    "            for sent in nltk.sent_tokenize(self._corpus[name]):\n",
    "                unique_words = set().union(unique_words, set(self._word_tokenize(sent)))\n",
    "                \n",
    "        for word in unique_words:\n",
    "            num_apps = sum(1 for name in fnames if word in self._corpus[name])\n",
    "            if num_apps > 0:\n",
    "                file_idfs[word] = log1p(num_docs / num_apps)\n",
    "        \n",
    "        return file_idfs\n",
    "\n",
    "    def _top_files_idf(self, query, idfs):\n",
    "        tf_idfs = { fname: 0 for fname in self._corpus }\n",
    "\n",
    "        query = self._word_tokenize(query)\n",
    "\n",
    "        for w in query:\n",
    "            for fname in self._corpus:\n",
    "                tf_idfs[fname] += self._corpus[fname].count(w) * idfs.get(w, 0)\n",
    "        \n",
    "        ranked_files = sorted(\n",
    "            tf_idfs.items(),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        return [file[0] for file in ranked_files][:self._file_matches]\n",
    "    \n",
    "    def _top_files_cosine(self, query, fnames):\n",
    "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "        ranked_files = sorted([\n",
    "            (name, self._cosine_similarity(query, self._corpus[name], model))\n",
    "            for name in fnames\n",
    "        ], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return [file[0] for file in ranked_files][:self._file_matches]\n",
    "    \n",
    "    def _word_tokenize(self, words):\n",
    "        banned = list(punctuation) + nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "        return [\n",
    "            w.lower() for w in nltk.word_tokenize(words)\n",
    "            if w.lower() not in banned\n",
    "        ]\n",
    "    \n",
    "    def _sent_rank_idf(self, query, context, idfs):\n",
    "        query_set = set(self._word_tokenize(query))\n",
    "        sent_scores = { sent: [0,0] for sent in nltk.sent_tokenize(context)}\n",
    "\n",
    "        for sent in sent_scores:\n",
    "            sent_set = set(self._word_tokenize(sent))\n",
    "            common_words = query_set.intersection(sent_set)\n",
    "            sent_scores[sent][0] += sum(idfs.get(w, 0) for w in common_words)\n",
    "            sent_scores[sent][1] += len(common_words)\n",
    "        \n",
    "        ranked_sents = sorted(\n",
    "            sent_scores.items(),\n",
    "            key=lambda x: (x[1][0], x[1][1]),\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        return [(sent, score[0]) for sent, score in ranked_sents]\n",
    "\n",
    "    def _sent_rank_cosine(self, query, context):\n",
    "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        sent_scores = {\n",
    "            sent: self._cosine_similarity(query, sent, model)\n",
    "            for sent in nltk.sent_tokenize(context)\n",
    "        }\n",
    "    \n",
    "        ranked_sents = sorted(\n",
    "            sent_scores.items(),\n",
    "            key = lambda x: x[1],\n",
    "            reverse=True\n",
    "        )\n",
    "    \n",
    "        return ranked_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f2b2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "crawler = DocSearcher()\n",
    "crawler.load_files('corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a79fe60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "And the output is...\n",
      "\n",
      "  While large, it is not always the apex predator in its range, yielding prey it has killed to American black bears, grizzly bears and packs of wolves. It is the largest cat native to the Americas and the third largest in the world, exceeded in size only by the tiger and the lion. With a body length of up to 1.85 m (6 ft 1 in) and a weight of up to 158 kg (348 lb), it is the largest cat species in the Americas and the third largest in the world. Small to mid-sized mammals are preferred, including large rodents such as the capybara. The largest recorded cougar, shot in 1901, weighed 105.2 kg (232 lb); claims of 125.2 kg (276 lb) and 118 kg (260 lb) have been reported, though they were probably exaggerated. The cougar holds the Guinness record for the animal with the greatest number of names, with over 40 in English alone. They prefer large mammals such as mule deer, white-tailed deer, elk, moose, mountain goat and bighorn sheep. They will opportunistically take smaller prey such as rodents, lagomorphs, smaller carnivores, birds and even domestic animals including pets. The cougar has the largest range of any wild land animal in the Americas, spanning 110 degrees of latitude from the Yukon Territory in Canada to the southern Andes in Chile. It is the second-largest cat in the New World, after the jaguar (Panthera onca). It has powerful jaws with the third-highest bite force of all felids, after the tiger and the lion. The cougar has large paws and proportionally the largest hind legs in the Felidae, allowing for its great leaping and short-sprint ability. An evaluation of JCUs from Mexico to Argentina revealed that they overlap with high-quality habitats of about 1,500 mammals to varying degrees. Its powerful forequarters, neck, and jaw serve to grasp and hold large prey. In South America, the jaguar is larger than the cougar and tends to take larger prey, usually over 22 kg (49 lb). The cougar's prey usually weighs between 2 and 22 kg (4 and 49 lb), which is thought to be the reason for its smaller size. They are the fourth largest cat species worldwide; adults stand about 60 to 90 cm (24 to 35 in) tall at the shoulders. Of the large predators in Yellowstone National Park – the grizzly bear, the black bear, the gray wolf, and the cougar – the massive grizzly bear appears dominant, often (but not always) able to drive a gray wolf pack, an American black bear, and a cougar off their kills.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' lion'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawler.search('What is the biggest animal?', s_method='cosine_sim', e_method='bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e925794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(nltk.sent_tokenize('Hello world. This is my story.')[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78faf8",
   "metadata": {},
   "source": [
    "# BERT Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "768a455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_two_point_O():\n",
    "    # Load model and tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "    model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "    \n",
    "    q_and_c = query_and_context()\n",
    "    long_text = q_and_c['context']\n",
    "    question = q_and_c['query']\n",
    "    text_len = len(long_text)\n",
    "    \n",
    "    # Chunking\n",
    "    max_length = 128\n",
    "    \n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for i in range(0, text_len, max_length):\n",
    "        chunk = long_text[i:i+max_length]\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            question,\n",
    "            chunk,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "        \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    # Stack the chunks of input IDs and attention masks\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Predict the output\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_masks)\n",
    "        start_logits, end_logits = outputs[:2]\n",
    "    \n",
    "    # Generate answer span\n",
    "    for i in range(len(input_ids)):\n",
    "        # Get the start and end indices of the answer span\n",
    "        start_ind = torch.argmax(start_logits[i])\n",
    "        end_ind = torch.argmax(end_logits[i])\n",
    "\n",
    "        # Use the indices to get the answer span from the input text\n",
    "        answer_text = tokenizer.decode(input_ids[i, start_ind:end_ind + 1], skip_special_tokens=True)\n",
    "\n",
    "        # Print the answer span\n",
    "        print(\"Answer: \", answer_text)\n",
    "    best_answer_ind = -1\n",
    "    max_start_logit = -1e10\n",
    "    max_end_logit = -1e10\n",
    "\n",
    "    for i in range(len(input_ids)):\n",
    "        # Get the start and end logits for this chunk\n",
    "        curr_start_logit = start_logits[i].max().item()\n",
    "        curr_end_logit = end_logits[i].max().item()\n",
    "\n",
    "        # Find the chunk with the highest start and end logits\n",
    "        if curr_start_logit + curr_end_logit > max_start_logit + max_end_logit:\n",
    "            max_start_logit = curr_start_logit\n",
    "            max_end_logit = curr_end_logit\n",
    "            best_answer_ind = i\n",
    "\n",
    "    # Use the best answer indices to get the answer span from the input text\n",
    "    start_ind = torch.argmax(start_logits[best_answer_ind])\n",
    "    end_ind = torch.argmax(end_logits[best_answer_ind])\n",
    "    answer_text = tokenizer.decode(input_ids[best_answer_ind, start_ind:end_ind + 1], skip_special_tokens=True)\n",
    "\n",
    "    # Print the answer span\n",
    "    print(\"===============\\n\\nAnswer: \", answer_text)\n",
    "    \n",
    "    return start_logits, end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1210d310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search term: Lionel Messi\n",
      "Enter your question: When was Lionel Messi found guilty of tax fraud?\n",
      "Answer:  \n",
      "Answer:  24 june 1987\n",
      "Answer:  \n",
      "Answer:  2020\n",
      "Answer:  2021\n",
      "Answer:  la liga\n",
      "Answer:  2021\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  13\n",
      "Answer:  october 2004\n",
      "Answer:  2008 – 09\n",
      "Answer:  three successful seasons followed, with messi winning four consecutive ballons d'or, making him t\n",
      "Answer:  2011 – 12 season\n",
      "Answer:  two seasons\n",
      "Answer:  \n",
      "Answer:  15 campaign\n",
      "Answer:  2015\n",
      "Answer:  august 2021\n",
      "Answer:  2005\n",
      "Answer:  2008\n",
      "Answer:  \n",
      "Answer:  august 2005\n",
      "Answer:  \n",
      "Answer:  2014\n",
      "Answer:  2015\n",
      "Answer:  2016\n",
      "Answer:  2019\n",
      "Answer:  2021\n",
      "Answer:  world cup\n",
      "Answer:  2006\n",
      "Answer:  2009 and 2014\n",
      "Answer:  2019 and 2022\n",
      "Answer:  020\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  24 june 1987\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  four\n",
      "Answer:  \n",
      "Answer:  shortly before his eleventh birthday\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  12\n",
      "Answer:  when he was six years old\n",
      "Answer:  87\n",
      "Answer:  aged 10\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  buenos aires club river plate\n",
      "Answer:  \n",
      "Answer:  september 2000\n",
      "Answer:  \n",
      "Answer:  14 december\n",
      "Answer:  february 2001\n",
      "Answer:  during his first year in spain\n",
      "Answer:  due to a transfer conflict with newell's\n",
      "Answer:  \n",
      "Answer:  mute. at home, he suffered from homesickness after his mother moved back to rosario\n",
      "Answer:  \n",
      "Answer:  february 2002\n",
      "Answer:  aged 14\n",
      "Answer:  2002 – 03\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  copa catalunya final\n",
      "Answer:  a week after suffering a broken cheekbone during a league match\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  barcelona\n",
      "Answer:  2003 – 04 season\n",
      "Answer:  arcelona\n",
      "Answer:  four international pre - season competitions\n",
      "Answer:  \n",
      "Answer:  ne of several youth players called up to strengthen a depleted first team during the international break\n",
      "Answer:  training session\n",
      "Answer:  \n",
      "Answer:  16 years, four months\n",
      "Answer:  \n",
      "Answer:  16 november 2003\n",
      "Answer:  \n",
      "Answer:  16\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  29 november\n",
      "Answer:  copa del rey match\n",
      "Answer:  4 february 2004\n",
      "Answer:  2012\n",
      "Answer:  segunda division b\n",
      "Answer:  \n",
      "Answer:  towards the end of the seas\n",
      "Answer:  campaign\n",
      "Answer:  2004 – 05 season\n",
      "Answer:  november\n",
      "Answer:  october 2004\n",
      "Answer:  \n",
      "Answer:  initially against the player's wishes\n",
      "Answer:  16 october\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  1 may 2005\n",
      "Answer:  barcelona, in their second season under rijkaard, won the leag\n",
      "Answer:  \n",
      "Answer:  18\n",
      "Answer:  august 2005\n",
      "Answer:  2010\n",
      "Answer:  24 august\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  triple his wages. according to then - president joan laporta, it was the only time the club faced a real risk of losing\n",
      "Answer:  16 september\n",
      "Answer:  2014\n",
      "Answer:  26 september\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  19 november\n",
      "Answer:  last 16 round of the champions league\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2 november 2005, his season ended prematurely during the return leg against chelsea on 7 march 2006\n",
      "Answer:  17 may\n",
      "Answer:  nal, he was eventually ruled out. he was so disappointed that he did not celebrate his team's victory over arsenal in paris, som\n",
      "Answer:  19\n",
      "Answer:  2006 – 07 campaign\n",
      "Answer:  36 games\n",
      "Answer:  2 november 2006\n",
      "Answer:  \n",
      "Answer:  10 m\n",
      "Answer:  2007\n",
      "Answer:  madrid to end the match in a 3 – 3 draw in injury time\n",
      "Answer:  month\n",
      "Answer:  during a copa del rey semi - final\n",
      "Answer:  \n",
      "Answer:  a world cup\n",
      "Answer:  \n",
      "Answer:  9 june\n",
      "Answer:  world cup match\n",
      "Answer:  copa del rey final\n",
      "Answer:  \n",
      "Answer:  2007\n",
      "Answer:  2007\n",
      "Answer:  \n",
      "Answer:  2007 – 08 campaign\n",
      "Answer:  15 december\n",
      "Answer:  during the return leg\n",
      "Answer:  march 2008\n",
      "Answer:  \n",
      "Answer:  league semi - finals\n",
      "Answer:  \n",
      "Answer:  july\n",
      "Answer:  ahead of the new season\n",
      "Answer:  2006 and 2008\n",
      "Answer:  argentina\n",
      "Answer:  four years\n",
      "Answer:  2008\n",
      "Answer:  2008 – 09 season\n",
      "Answer:  \n",
      "Answer:  during his first season\n",
      "Answer:  rijkaard\n",
      "Answer:  2 may 2009\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  13 may\n",
      "Answer:  \n",
      "Answer:  three days later\n",
      "Answer:  als, the youngest in the tournament's history, messi scored two goals and assisted two more to ensure a 4 – 0 quarter - final victor\n",
      "Answer:  27 may\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  18 september\n",
      "Answer:  2009\n",
      "Answer:  \n",
      "Answer:  august, barcelona won the fifa club world cup against estudiantes de la plata on 19 december\n",
      "Answer:  22 years old\n",
      "Answer:  \n",
      "Answer:  station\n",
      "Answer:  april 2010\n",
      "Answer:  round of 16\n",
      "Answer:  2010\n",
      "Answer:  last 16 - round match\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  1996 – 97\n",
      "Answer:  6 april\n",
      "Answer:  champions league semi - finals\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2010 – 11\n",
      "Answer:  \n",
      "Answer:  29 november 2010\n",
      "Answer:  real madrid\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2010\n",
      "Answer:  ld format, he would have placed just outside the top three\n",
      "Answer:  16 april\n",
      "Answer:  after barcelona lost the copa del rey final four days later\n",
      "Answer:  champions league semi - finals\n",
      "Answer:  \n",
      "Answer:  champions league final\n",
      "Answer:  the final two years earlier\n",
      "Answer:  28 may\n",
      "Answer:  la liga\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2011 – 12 season\n",
      "Answer:  \n",
      "Answer:  supercopa de espana\n",
      "Answer:  18 december\n",
      "Answer:  \n",
      "Answer:  2011\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  march 2012\n",
      "Answer:  7 march\n",
      "Answer:  champions league last 16 - round match\n",
      "Answer:  found guilty of tax fraud? ition\n",
      "Answer:  1962 – 63\n",
      "Answer:  20 march\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  25 may\n",
      "Answer:  champions league semi - finals\n",
      "Answer:  5 may\n",
      "Answer:  season\n",
      "Answer:  la liga\n",
      "Answer:  1972 – 73\n",
      "Answer:  14\n",
      "Answer:  2012\n",
      "Answer:  9 december\n",
      "Answer:  \n",
      "Answer:  1972\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2013\n",
      "Answer:  2012 – 13\n",
      "Answer:  \n",
      "Answer:  eliminated in the first knockout round of the champions league by ac milan, but a revival of form in the second leg\n",
      "Answer:  ninth senior season with barcelona\n",
      "Answer:  7 february\n",
      "Answer:  17 march\n",
      "Answer:  \n",
      "Answer:  three years earlier\n",
      "Answer:  leo\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  april 2013\n",
      "Answer:  2 april\n",
      "Answer:  in the second leg against psg\n",
      "Answer:  bench in the second half and within nine minutes\n",
      "Answer:  - finals\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  tax fraud\n",
      "Answer:  2013\n",
      "Answer:  12 may\n",
      "Answer:  four - goal display against osasuna\n",
      "Answer:  la liga\n",
      "Answer:  \n",
      "Answer:  following an irregular start to the new season\n",
      "Answer:  2013\n",
      "Answer:  o months\n",
      "Answer:  2013 – 14 season\n",
      "Answer:  2014\n",
      "Answer:  \n",
      "Answer:  16 march\n",
      "Answer:  23 march\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  19 may 2014\n",
      "Answer:  ual update ; his salary increased to €20 million, or €36 million before taxes\n",
      "Answer:  chelsea\n",
      "Answer:  2014 – 15\n",
      "Answer:  towards the end of the year. a hat - trick scored against sevilla on 22 november\n",
      "Answer:  la liga\n",
      "Answer:  7 december\n",
      "Answer:  \n",
      "Answer:  2015\n",
      "Answer:  11 january\n",
      "Answer:  a 3 – 1 victory over atletico madrid\n",
      "Answer:  \n",
      "Answer:  late the previous year\n",
      "Answer:  found guilty of tax fraud?\n",
      "Answer:  \n",
      "Answer:  towards the end of the campaign, messi scored in a 1 – 0 away win over atletico madrid on 17 may\n",
      "Answer:  8 march\n",
      "Answer:  32nd hat - trick overall for barcelona\n",
      "Answer:  la liga\n",
      "Answer:  15 february\n",
      "Answer:  30 may\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  champions league\n",
      "Answer:  twice\n",
      "Answer:  three minutes after his first, saw him chip the ball over goalkeeper manuel neuer after his dribble past j\n",
      "Answer:  \n",
      "Answer:  6 june\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  five champions league seasons\n",
      "Answer:  2015 – 16\n",
      "Answer:  16 september\n",
      "Answer:  \n",
      "Answer:  21 november\n",
      "Answer:  2015\n",
      "Answer:  30 december\n",
      "Answer:  11 january 2016\n",
      "Answer:  copa del rey semi - final\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  17 february\n",
      "Answer:  \n",
      "Answer:  2015 – 16 uefa champions league round of 16\n",
      "Answer:  17 april\n",
      "Answer:  2015 – 16 season\n",
      "Answer:  2016 copa del rey final, at the vicente calderon stadium, on 22 may 2016\n",
      "Answer:  \n",
      "Answer:  spanish record of 131 goals throughout the season, breaking the record they had set the previous season\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2016 – 17 season by lifting the 2016\n",
      "Answer:  14 august\n",
      "Answer:  17 august\n",
      "Answer:  2016 – 17 la liga season\n",
      "Answer:  2016 – 17\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  16 october\n",
      "Answer:  1 november\n",
      "Answer:  3 – 1 away loss to manchester city\n",
      "Answer:  2016\n",
      "Answer:  9 january 2017\n",
      "Answer:  11 january\n",
      "Answer:  the round of 16 of the copa del rey\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  14 january\n",
      "Answer:  4 february 2017\n",
      "Answer:  rcelona in a 3 – 0 home win over athletic bilbao in the league\n",
      "Answer:  23 april\n",
      "Answer:  barcelona\n",
      "Answer:  27 may\n",
      "Answer:  2016 – 17\n",
      "Answer:  la liga\n",
      "Answer:  2017 – 18\n",
      "Answer:  madrid in supercopa de espana\n",
      "Answer:  9 september\n",
      "Answer:  \n",
      "Answer:  12 september\n",
      "Answer:  19 september\n",
      "Answer:  ober\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  18 october\n",
      "Answer:  100th in all uefa club competitions, in a 3 – 1 home victory over olympiacos.\n",
      "Answer:  \n",
      "Answer:  4 november\n",
      "Answer:  25 november\n",
      "Answer:  7 january 2018\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  a week\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  found guilty of tax fraud? e counterpart\n",
      "Answer:  7 april\n",
      "Answer:  in a 3 – 1 win over leganes\n",
      "Answer:  la liga\n",
      "Answer:  21 april\n",
      "Answer:  2018\n",
      "Answer:  29 april\n",
      "Answer:  9 may\n",
      "Answer:  may 2018\n",
      "Answer:  12 august\n",
      "Answer:  19 august\n",
      "Answer:  season\n",
      "Answer:  18 september\n",
      "Answer:  20 oct\n",
      "Answer:  26th minute\n",
      "Answer:  on 8\n",
      "Answer:  december\n",
      "Answer:  la liga\n",
      "Answer:  la liga\n",
      "Answer:  13 january 2019\n",
      "Answer:  2 february\n",
      "Answer:  scored twice in a 2 – 2 draw against valencia, with his first goal coming from the penalty spot, his 50th la liga\n",
      "Answer:  \n",
      "Answer:  23 february\n",
      "Answer:  \n",
      "Answer:  la liga\n",
      "Answer:  16 april\n",
      "Answer:  inals to give barcelona a 4 – 0 aggregate win\n",
      "Answer:  27 april\n",
      "Answer:  \n",
      "Answer:  1 may\n",
      "Answer:  liverpool in the first leg of the champions league semi - finals\n",
      "Answer:  six days later at anfield\n",
      "Answer:  19 may\n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud? mpetitions ), which saw him capture his sixth pichichi trophy as the league's top scorer, with 36 goals in 34 appearances ; with s\n",
      "Answer:  la liga\n",
      "Answer:  25 may\n",
      "Answer:  2019 copa del rey final. on 5 august 2019\n",
      "Answer:  19 august\n",
      "Answer:  2019\n",
      "Answer:  opening game of the season\n",
      "Answer:  september\n",
      "Answer:  2019\n",
      "Answer:  6 october\n",
      "Answer:  la liga\n",
      "Answer:  23 october\n",
      "Answer:  champions league seasons\n",
      "Answer:  ing rounds\n",
      "Answer:  29 october\n",
      "Answer:  \n",
      "Answer:  9 november\n",
      "Answer:  27 november\n",
      "Answer:  uefa champions lea\n",
      "Answer:  34th\n",
      "Answer:  2 december\n",
      "Answer:  22 february 2020\n",
      "Answer:  14 june\n",
      "Answer:  30 june\n",
      "Answer:  11 july\n",
      "Answer:  20th assist of the league season\n",
      "Answer:  2008 to 2009\n",
      "Answer:  2002 – 03\n",
      "Answer:  ts in a single league season\n",
      "Answer:  20 may\n",
      "Answer:  goals and 21 assists\n",
      "Answer:  9 august\n",
      "Answer:  mp nou\n",
      "Answer:  15 august\n",
      "Answer:  lisbon\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  4 september 2020\n",
      "Answer:  \n",
      "Answer:  25 august 2020\n",
      "Answer:  26 august\n",
      "Answer:  \n",
      "Answer:  leave should a buyer pay his €700 million buyout clause\n",
      "Answer:  \n",
      "Answer:  31 may 2020\n",
      "Answer:  4 september\n",
      "Answer:  la liga\n",
      "Answer:  2019 – 20 season\n",
      "Answer:  30 august\n",
      "Answer:  that evening\n",
      "Answer:  interview\n",
      "Answer:  end of every season\n",
      "Answer:  \n",
      "Answer:  27 september\n",
      "Answer:  two days prior to the opening game\n",
      "Answer:  20 october\n",
      "Answer:  champions league\n",
      "Answer:  2020\n",
      "Answer:  29 november\n",
      "Answer:  er scoring, he unveiled a shirt of his former side newell's old boys, in tribute to argentine compatriot diego maradona, who had\n",
      "Answer:  four days earlier\n",
      "Answer:  1993\n",
      "Answer:  \n",
      "Answer:  fourteenth consecutive year\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  23 december\n",
      "Answer:  tax fraud\n",
      "Answer:  17 january 2021\n",
      "Answer:  club career for violent conduct ( swinging an arm at the head of asier villalibre, missed initially by the referee but reviewed\n",
      "Answer:  in the final minutes of barcelona's 2 – 3 extra time defeat to athletic bilbao in the 2020 – 21 supercopa de espana final\n",
      "Answer:  10 march\n",
      "Answer:  champions league round of 16\n",
      "Answer:  16 february\n",
      "Answer:  15 march\n",
      "Answer:  21 march\n",
      "Answer:  17 april\n",
      "Answer:  2021\n",
      "Answer:  35th trophy with barcelona\n",
      "Answer:  16 may\n",
      "Answer:  30th league goal of the campaign\n",
      "Answer:  la liga\n",
      "Answer:  la liga\n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  \n",
      "Answer:  1 july\n",
      "Answer:  5 august\n",
      "Answer:  that day\n",
      "Answer:  ##ions\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  three days\n",
      "Answer:  10 august\n",
      "Answer:  june 2023\n",
      "Answer:  \n",
      "Answer:  9 august\n",
      "Answer:  15 september\n",
      "Answer:  28 september\n",
      "Answer:  21 november\n",
      "Answer:  3 – 1 home victory over nantes. later that month, he provided a hat - trick of assists for the fifth time in his caree\n",
      "Answer:  \n",
      "Answer:  2021\n",
      "Answer:  le\n",
      "Answer:  \n",
      "Answer:  first season\n",
      "Answer:  2 january 2022\n",
      "Answer:  23 january\n",
      "Answer:  13 march\n",
      "Answer:  round of 16\n",
      "Answer:  in the league match against bordeaux\n",
      "Answer:  a year of learning\n",
      "Answer:  23 april\n",
      "Answer:  \n",
      "Answer:  season with 11 goals and 14 assists across all competitions. he failed to reach double figure league goals for the first time si\n",
      "Answer:  2005 – 06\n",
      "Answer:  galtier\n",
      "Answer:  season\n",
      "Answer:  31 july\n",
      "Answer:  last season\n",
      "Answer:  2005\n",
      "Answer:  \n",
      "Answer:  5 october\n",
      "Answer:  champions league\n",
      "Answer:  25 october\n",
      "Answer:  haifa\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2021 – 22 season\n",
      "Answer:  2003\n",
      "Answer:  \n",
      "Answer:  childhood\n",
      "Answer:  june 2004\n",
      "Answer:  29 june\n",
      "Answer:  \n",
      "Answer:  february 2005\n",
      "Answer:  \n",
      "Answer:  last match against brazil, thereby securing their third - place qualification for the fif\n",
      "Answer:  a world youth championship. aware of his physical limitations, messi employed a personal trainer to increase his muscle mass, re\n",
      "Answer:  june\n",
      "Answer:  first match against the united states\n",
      "Answer:  \n",
      "Answer:  knockout phase\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  argentina\n",
      "Answer:  1979\n",
      "Answer:  \n",
      "Answer:  17 august 2005\n",
      "Answer:  rd minute\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  september\n",
      "Answer:  next qualifying match\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  2006\n",
      "Answer:  a week later jeopardised his presence in the world cup\n",
      "Answer:  during the world cup in germany\n",
      "Answer:  in the next match, against serbia and montenegro\n",
      "Answer:  fifa world cup when he came on as a substitute in the 74th minute\n",
      "Answer:  found guilty of tax fraud?\n",
      "Answer:  \n",
      "Answer:  eral starters were rested during the last group match\n",
      "Answer:  round of 16 match against mexico, played on his 19th birthday\n",
      "Answer:  in the 84th minute\n",
      "Answer:  quarter - final\n",
      "Answer:  \n",
      "Answer:  argentina\n",
      "Answer:  \n",
      "Answer:  2007\n",
      "Answer:  in the opening match\n",
      "Answer:  quarter - final stage\n",
      "Answer:  semi - final\n",
      "Answer:  the final\n",
      "Answer:  argentina\n",
      "Answer:  ahead of the 2008 summer\n",
      "Answer:  olympics\n",
      "Answer:  qualifying matches\n",
      "Answer:  92\n",
      "Answer:  following a 1 – 0 win in the next group match against australia\n",
      "Answer:  final qualification\n",
      "Answer:  against the netherlands\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  late 2008\n",
      "Answer:  2010\n",
      "Answer:  last qualifying match\n",
      "Answer:  eight qualifying matches\n",
      "Answer:  \n",
      "Answer:  28 march 2009\n",
      "Answer:  ahead of the tournament\n",
      "Answer:  barcelona\n",
      "Answer:  argentine football\n",
      "Answer:  world cup\n",
      "Answer:  opening match\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  aranteed\n",
      "Answer:  2 – 0 win against greece\n",
      "Answer:  quarter - final\n",
      "Answer:  four years earlier\n",
      "Answer:  1974\n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud? rsher judgement\n",
      "Answer:  1986\n",
      "Answer:  \n",
      "Answer:  olympic victory. batista publicly stated that he intended to build the team around messi, employing him as a false nine wi\n",
      "Answer:  2010 – 11\n",
      "Answer:  march 2009\n",
      "Answer:  2011\n",
      "Answer:  argentine\n",
      "Answer:  during the crucial next match\n",
      "Answer:  \n",
      "Answer:  quarter - final\n",
      "Answer:  \n",
      "Answer:  august 2011\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  sabella\n",
      "Answer:  olympic games\n",
      "Answer:  7 october\n",
      "Answer:  \n",
      "Answer:  three years. he netted a total of 12 goals in 9 games for argentina\n",
      "Answer:  2012\n",
      "Answer:  29 february 2012\n",
      "Answer:  2014\n",
      "Answer:  10 september 2013\n",
      "Answer:  \n",
      "Answer:  during the qualifying campaign\n",
      "Answer:  ahead of the world cup in brazil\n",
      "Answer:  at the start of the tournament\n",
      "Answer:  first world cup match\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  the second match against iran\n",
      "Answer:  ##ication for the knockout phase\n",
      "Answer:  om a free kick, as they finished first in their group. messi assisted a late goal in extra time\n",
      "Answer:  in the round of 16\n",
      "Answer:  1990\n",
      "Answer:  ty shootout to reach the final\n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  at the start of the second half\n",
      "Answer:  113th minute\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2015\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  22 of which came in official competitive matches. as messi evolved from the team's symbolic\n",
      "Answer:  ain into a genuine leader, he led argentina to the knockout stage as group winners. in the quarter - final\n",
      "Answer:  \n",
      "Answer:  semi - final\n",
      "Answer:  stage\n",
      "Answer:  final\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  rt his penalty\n",
      "Answer:  1993\n",
      "Answer:  \n",
      "Answer:  27\n",
      "Answer:  may 2016\n",
      "Answer:  6 june\n",
      "Answer:  10 june\n",
      "Answer:  in the 61st minute\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  argentina\n",
      "Answer:  18 june\n",
      "Answer:  copa america\n",
      "Answer:  \n",
      "Answer:  three days later when messi scored a free kick in a 4 – 0 semi - final win against hosts the united states ; he a\n",
      "Answer:  final of the competition\n",
      "Answer:  26 june\n",
      "Answer:  chile on penalties after a 0 – 0 deadlock\n",
      "Answer:  after the match\n",
      "Answer:  chile\n",
      "Answer:  after the match\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  \n",
      "Answer:  argentina\n",
      "Answer:  when the team landed in buenos aires\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  2 july\n",
      "Answer:  the night of the final\n",
      "Answer:  12 august 2016\n",
      "Answer:  ek after messi announced his international retirement\n",
      "Answer:  2018 fifa world cup qualifiers in september\n",
      "Answer:  2018\n",
      "Answer:  1 september\n",
      "Answer:  march 2017\n",
      "Answer:  2017\n",
      "Answer:  argentina football association appealed against his suspension, which meant he could now play argentina's remaining world cup q\n",
      "Answer:  2018\n",
      "Answer:  \n",
      "Answer:  1970\n",
      "Answer:  2001\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2018 world cup\n",
      "Answer:  march 2018\n",
      "Answer:  16 june\n",
      "Answer:  21 june\n",
      "Answer:  argentina\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  argentina's final group match against nigeria\n",
      "Answer:  26 june\n",
      "Answer:  three different world cups\n",
      "Answer:  thirties\n",
      "Answer:  ass from midfield\n",
      "Answer:  r right foot. he was awarded man of the match. argentina progressed to the second round\n",
      "Answer:  30 june\n",
      "Answer:  \n",
      "Answer:  last four world cups\n",
      "Answer:  1986\n",
      "Answer:  september\n",
      "Answer:  unlikely that he would represent his nation for the remainder of the calendar year\n",
      "Answer:  \n",
      "Answer:  march 2019\n",
      "Answer:  later that month. a conversation with scaloni and his idol aimar made messi reconsider his de\n",
      "Answer:  21 may\n",
      "Answer:  2019\n",
      "Answer:  19 june\n",
      "Answer:  quarter - finals\n",
      "Answer:  28 june\n",
      "Answer:  2 july\n",
      "Answer:  in the third - place match\n",
      "Answer:  uly\n",
      "Answer:  37th minute of play\n",
      "Answer:  following the match\n",
      "Answer:  semi - final\n",
      "Answer:  2 august\n",
      "Answer:  e months\n",
      "Answer:  15 november\n",
      "Answer:  2019\n",
      "Answer:  8 october 2020\n",
      "Answer:  \n",
      "Answer:  14 june\n",
      "Answer:  2021\n",
      "Answer:  21 june\n",
      "Answer:  in a 1 – 0 win over paraguay in their third game of the tournament\n",
      "Answer:  argentina shirt when he featured in a 4 – 1 win against bolivia in his team's final group match\n",
      "Answer:  3 july\n",
      "Answer:  6 july\n",
      "Answer:  fifth assist of the tournament, a cut - back for lautaro martinez, matching his record of nine goal con\n",
      "Answer:  five years earlier\n",
      "Answer:  10 july\n",
      "Answer:  1993\n",
      "Answer:  argentina\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  9 sep\n",
      "Answer:  2022\n",
      "Answer:  2022 finalissima\n",
      "Answer:  2 june 2022\n",
      "Answer:  6 june\n",
      "Answer:  in a 5 – 0 victory in a friendly win over estonia\n",
      "Answer:  2022\n",
      "Answer:  \n",
      "Answer:  last 16 game against australia\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  in the quarter - final\n",
      "Answer:  argentina won 4 – 3 in the penalty shootout\n",
      "Answer:  semi - final\n",
      "Answer:  found guilty of tax fraud?\n",
      "Answer:  11th world cup\n",
      "Answer:  world cup\n",
      "Answer:  2022\n",
      "Answer:  lusail stadium\n",
      "Answer:  1986\n",
      "Answer:  extra - time\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  world cup\n",
      "Answer:  st\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  tackles\n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  \n",
      "Answer:  et enable him to retain control of the ball when dribbling at speed. his former barcelona manager pep guardiola once stated, \" me\n",
      "Answer:  tax fraud\n",
      "Answer:  mid - 20s\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  october 2022\n",
      "Answer:  \n",
      "Answer:  during counterattacks\n",
      "Answer:  \n",
      "Answer:  mer argentina\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  pitch\n",
      "Answer:  \n",
      "Answer:  ight wing by manager frank rijkaard\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  enrique\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  tax fraud\n",
      "Answer:  \n",
      "Answer:  tax fraud\n",
      "Answer:  \n",
      "Answer:  tax fraud\n",
      "Answer:  career progressed\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  season\n",
      "Answer:  early career\n",
      "Answer:  argentina\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  february 2006\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  four years later\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2009\n",
      "Answer:  the end of barca's second treble - winning season\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2021\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  1986\n",
      "Answer:  the last five years, messi has been the maradona of the world cup in mexico\n",
      "Answer:  978 world cup victory\n",
      "Answer:  \n",
      "Answer:  2019\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  argentine\n",
      "Answer:  \n",
      "Answer:  2019\n",
      "Answer:  \n",
      "Answer:  13\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  argentina\n",
      "Answer:  2019\n",
      "Answer:  2022\n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2008\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  20\n",
      "Answer:  09 – 10 to 2017 – 18\n",
      "Answer:  \n",
      "Answer:  2009 and 2014\n",
      "Answer:  2013\n",
      "Answer:  2014\n",
      "Answer:  2018\n",
      "Answer:  nchmark for a calendar year\n",
      "Answer:  2019\n",
      "Answer:  2017\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  2020\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  2010\n",
      "Answer:  14\n",
      "Answer:  2008\n",
      "Answer:  2015\n",
      "Answer:  2015\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  \n",
      "Answer:  at the start of his career\n",
      "Answer:  2010\n",
      "Answer:  yer, his marketing appeal widened, leading to long - term endorsement deals with luxury brands dolce & gabbana and audemars piguet\n",
      "Answer:  \n",
      "Answer:  2009\n",
      "Answer:  2011\n",
      "Answer:  fifa 13 to fifa 16\n",
      "Answer:  2011 and 2012\n",
      "Answer:  april 2011\n",
      "Answer:  august 2021\n",
      "Answer:  st\n",
      "Answer:  18 december 2022\n",
      "Answer:  2014\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  march\n",
      "Answer:  2011\n",
      "Answer:  \n",
      "Answer:  2005\n",
      "Answer:  \n",
      "Answer:  2014\n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  may 2022\n",
      "Answer:  \n",
      "Answer:  august 2022\n",
      "Answer:  2017\n",
      "Answer:  2008\n",
      "Answer:  five years old\n",
      "Answer:  january 2009\n",
      "Answer:  a month later during a carnival in sitges after the barcelona – espanyol derby\n",
      "Answer:  1997 to 2001\n",
      "Answer:  2012\n",
      "Answer:  2 june 2012\n",
      "Answer:  april 2015\n",
      "Answer:  30 june 2017\n",
      "Answer:  october 2017\n",
      "Answer:  \n",
      "Answer:  on his left shoulder\n",
      "Answer:  14\n",
      "Answer:  \n",
      "Answer:  13\n",
      "Answer:  \n",
      "Answer:  once when he was in training\n",
      "Answer:  buenos aires\n",
      "Answer:  buenos aires the next day\n",
      "Answer:  87\n",
      "Answer:  at newell's old boys\n",
      "Answer:  2012\n",
      "Answer:  rosario\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  2004\n",
      "Answer:  unicef\n",
      "Answer:  march 2010\n",
      "Answer:  bring public awareness to the plight of the country's children in the wake of the recent earthquake\n",
      "Answer:  \n",
      "Answer:  november 2013\n",
      "Answer:  \n",
      "Answer:  2007\n",
      "Answer:  boston\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  tax fraud\n",
      "Answer:  \n",
      "Answer:  argentina\n",
      "Answer:  2013\n",
      "Answer:  tax fraud\n",
      "Answer:  2012\n",
      "Answer:  tax fraud\n",
      "Answer:  7 june 2016\n",
      "Answer:  found guilty of tax fraud? n newspaper\n",
      "Answer:  found guilty of tax fraud\n",
      "Answer:  spain and his native argentina\n",
      "Answer:  2020\n",
      "Answer:  november 2016\n",
      "Answer:  gency\n",
      "Answer:  february 2021\n",
      "Answer:  when he scored his 644th goal\n",
      "Answer:  april\n",
      "Answer:  2021\n",
      "Answer:  \n",
      "Answer:  \n",
      "Answer:  uruguay\n",
      "Answer:  pread vaccine scarcity in the region, with the mayor of canelones in uruguay\n",
      "Answer:  copa america\n",
      "Answer:  2013\n",
      "Answer:  between 2007 and 2009\n",
      "Answer:  2012\n",
      "Answer:  6 july 2016\n",
      "Answer:  \n",
      "Answer:  €1. 4 million\n",
      "Answer:  barcelona paris saint - germain argentina\n",
      "Answer:  u20 argentina u23 argentina\n",
      "===============\n",
      "\n",
      "Answer:  6 july 2016\n"
     ]
    }
   ],
   "source": [
    "start_logits, end_logits = bert_two_point_O()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1341677",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_three_point_O():\n",
    "    # Load the pre-trained model\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "    # Define a text passage and question to be answered\n",
    "    q_and_c = query_and_context()\n",
    "    question = q_and_c['query']\n",
    "    text = q_and_c['context']\n",
    "\n",
    "    # Split the text into smaller segments\n",
    "    segment_length = 512 - 2 - len(tokenizer.tokenize(question))\n",
    "    segments = [text[i:i + segment_length] for i in range(0, len(text), segment_length)]\n",
    "\n",
    "    # Tokenize the question\n",
    "    question_tokens = tokenizer.tokenize(question)\n",
    "\n",
    "    # Initialize start and end scores for each segment\n",
    "    start_scores = []\n",
    "    end_scores = []\n",
    "\n",
    "    # Use BERT to get the start and end scores for each segment\n",
    "    for i, segment in enumerate(segments):\n",
    "        input_ids = tokenizer.encode(question, segment)\n",
    "        input_ids = torch.tensor([input_ids]).long()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            start_scores.append(outputs[0][0].squeeze()[:segment_length + 2])\n",
    "            end_scores.append(outputs[1][0].squeeze()[:segment_length + 2])\n",
    "    \n",
    "    # Pad the start and end scores so they have the same shape\n",
    "    max_len = max([s.shape[0] for s in start_scores])\n",
    "    start_scores = [torch.cat([s, torch.zeros(max_len - s.shape[0])]) for s in start_scores]\n",
    "    end_scores = [torch.cat([s, torch.zeros(max_len - s.shape[0])]) for s in end_scores]\n",
    "\n",
    "    # Combine the start and end scores for all segments\n",
    "    start_scores = torch.stack(start_scores).mean(dim=0)\n",
    "    end_scores = torch.stack(end_scores).mean(dim=0)\n",
    "\n",
    "    # Get the indices of the start and end of the answer\n",
    "    answer_start = torch.argmax(start_scores)\n",
    "    answer_end = torch.argmax(end_scores)\n",
    "\n",
    "    # Get the tokenized answer\n",
    "    answer_tokens = input_ids[0][answer_start:answer_end + 1]\n",
    "\n",
    "    # Convert the tokenized answer back to text\n",
    "    answer = tokenizer.decode(answer_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe04129a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search term: Tom Cruise\n",
      "Enter your question: Where did Tom Cruise grow up?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_three_point_O()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "960d583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search term: Tom Cruise\n",
      "Enter your question: Who is Tom Cruise?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_three_point_O()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5dd56dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a search term: Nico Ditch\n",
      "Enter your question: Where is Nico Ditch?\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mbert_three_point_O\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[62], line 7\u001b[0m, in \u001b[0;36mbert_three_point_O\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-large-uncased-whole-word-masking-finetuned-squad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Define a text passage and question to be answered\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m q_and_c \u001b[38;5;241m=\u001b[39m \u001b[43mquery_and_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m question \u001b[38;5;241m=\u001b[39m q_and_c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m text \u001b[38;5;241m=\u001b[39m q_and_c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mquery_and_context\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m context \u001b[38;5;241m=\u001b[39m search(term)\n\u001b[1;32m      5\u001b[0m query \u001b[38;5;241m=\u001b[39m get_text_cli(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter your question\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m: query, \n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mcontext\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext_title\u001b[39m\u001b[38;5;124m'\u001b[39m: context[\u001b[38;5;241m1\u001b[39m], \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m: context[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     11\u001b[0m }\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "bert_three_point_O()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
